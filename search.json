[
  {
    "objectID": "clients.html",
    "href": "clients.html",
    "title": "Clients & Methods",
    "section": "",
    "text": "Before you instantiate a class, remember authenticating using any of the following methods.\n\nUsing the Google Cloud SDK(installation needed):\n\n\n#!gcloud auth login --update-adc\n\n\nDownloading a service account JSON keyfile and point to it using an environment variable:\n\n\n#!export GOOGLE_APPLICATION_CREDENTIALS=\"/path/to/keyfile.json\"\n\n\nsource\n\n\n\n BigQuery (project_id:str)\n\nBigQuery client generation and additional methods\n\n\n\n\nType\nDetails\n\n\n\n\nproject_id\nstr\nGCP project ID\n\n\n\nExample 1: using the BigQuery client to perform a query job.\n\n# 1. Instantiate object:\nPROJECT_ID = 'dz-learning-d'\nbq_obj = BigQuery(PROJECT_ID)\n\n# 2. Execute job:\nDATASET = 'new_dataset'\nTABLE = 'new_view'\nQUERY = \"\"\"\n        CREATE SCHEMA IF NOT EXISTS {dataset}\n        OPTIONS(\n        location=\"us\",\n        default_table_expiration_days=3.75,\n        labels=[(\"purpose\",\"learning\"),(\"project\",\"package\")]\n        );\n\n        CREATE OR REPLACE VIEW `{project_id}.{dataset}.{table}`\n        OPTIONS(\n        expiration_timestamp=TIMESTAMP_ADD(\n                CURRENT_TIMESTAMP(), INTERVAL 48 HOUR),\n        friendly_name=\"new_view\",\n        description=\"a view that expires in 2 days\",\n        labels=[(\"purpose\", \"learning\")]\n        )\n        AS SELECT name, state, year, number\n        FROM `bigquery-public-data.usa_names.usa_1910_current`\n        WHERE state LIKE 'W%'\n        \"\"\".format(project_id = PROJECT_ID, dataset = DATASET, table = TABLE)\n\njob = bq_obj.client.query(QUERY)  # API request.\njob.result()  # Waits for the query to finish.\nprint(job)\n\nQueryJob&lt;project=dz-learning-d, location=US, id=9a4cd539-d063-429d-bff8-1a7b64a6620c&gt;\n\n\nWhich results in a brand new dataset and view on our project: \nExample 2: using the BigQuery client to perform a SQL query and save the results in a dataframe.\n\n# 1. Instantiate object:\nPROJECT_ID = 'dz-learning-d'\nbq_obj = BigQuery(PROJECT_ID)\n\n# 2. Execute SQL and save results in dataframe:\nQUERY = \"\"\"\n        SELECT name FROM `bigquery-public-data.usa_names.usa_1910_2013`\n        WHERE state = \"TX\"\n        LIMIT 100\n        \"\"\"\ndf = bq_obj.client.query(QUERY).to_dataframe()\ndf\n\n\n\n\n\n\n\n\nname\n\n\n\n\n0\nMary\n\n\n1\nRoberta\n\n\n2\nMarguerite\n\n\n3\nKatie\n\n\n4\nEunice\n\n\n...\n...\n\n\n95\nRita\n\n\n96\nElida\n\n\n97\nBillie\n\n\n98\nIda\n\n\n99\nElizabeth\n\n\n\n\n100 rows × 1 columns\n\n\n\n\n# Test [extract_bucket_and_path]:\nt_bucket = 'bucket_name'\nt_path = 'folder_name_1/folder_name_2'\nf_bucket, f_path = extract_bucket_and_path('gs://bucket_name/folder_name_1/folder_name_2')\n\ntest_eq(t_bucket, f_bucket)\ntest_eq(t_path, f_path)\n\n\nsource\n\n\n\n\n Storage (project_id:str)\n\nCloud Storage client generation and additional methods\n\n\n\n\nType\nDetails\n\n\n\n\nproject_id\nstr\nGCP project ID\n\n\n\n\nsource\n\n\n\n\n Storage.download_files (gcs_uri:str, local_dir:str='', verbose:bool=True)\n\nDownload the files from a GCS location to a local directory\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ngcs_uri\nstr\n\nGCS URI. Ex: gs://bucket_name/[folder_name/]\n\n\nlocal_dir\nstr\n\nLocal directory to download the file\n\n\nverbose\nbool\nTrue\nBoolean variable to print paths of files downloaded\n\n\n\n\n# 1. Instantiate object:\nPROJECT_ID = 'dz-learning-d'\nstg_obj = Storage(PROJECT_ID)\n\n# 2. Download files from GCS location to local:\nGCS_URI = 'gs://dz-d-stg-us-testartifacts/gcp-python-client-funtions/01_storage/01_download_files_folder/'\nLOCAL_DIR = 'test_sandbox/01_storage'\n\nres = stg_obj.download_files(GCS_URI, LOCAL_DIR, False)\nprint(res)\n\n# Test [download_files]:\ntest_eq(res, 'No. files downloaded: 4')\n\nNo. files downloaded: 4\n\n\nPortions of this page are modifications based on work created and shared by Google and used according to terms described in the Creative Commons 4.0 Attribution License."
  },
  {
    "objectID": "clients.html#authentication",
    "href": "clients.html#authentication",
    "title": "Clients & Methods",
    "section": "",
    "text": "Before you instantiate a class, remember authenticating using any of the following methods.\n\nUsing the Google Cloud SDK(installation needed):\n\n\n#!gcloud auth login --update-adc\n\n\nDownloading a service account JSON keyfile and point to it using an environment variable:\n\n\n#!export GOOGLE_APPLICATION_CREDENTIALS=\"/path/to/keyfile.json\"\n\n\nsource\n\n\n\n BigQuery (project_id:str)\n\nBigQuery client generation and additional methods\n\n\n\n\nType\nDetails\n\n\n\n\nproject_id\nstr\nGCP project ID\n\n\n\nExample 1: using the BigQuery client to perform a query job.\n\n# 1. Instantiate object:\nPROJECT_ID = 'dz-learning-d'\nbq_obj = BigQuery(PROJECT_ID)\n\n# 2. Execute job:\nDATASET = 'new_dataset'\nTABLE = 'new_view'\nQUERY = \"\"\"\n        CREATE SCHEMA IF NOT EXISTS {dataset}\n        OPTIONS(\n        location=\"us\",\n        default_table_expiration_days=3.75,\n        labels=[(\"purpose\",\"learning\"),(\"project\",\"package\")]\n        );\n\n        CREATE OR REPLACE VIEW `{project_id}.{dataset}.{table}`\n        OPTIONS(\n        expiration_timestamp=TIMESTAMP_ADD(\n                CURRENT_TIMESTAMP(), INTERVAL 48 HOUR),\n        friendly_name=\"new_view\",\n        description=\"a view that expires in 2 days\",\n        labels=[(\"purpose\", \"learning\")]\n        )\n        AS SELECT name, state, year, number\n        FROM `bigquery-public-data.usa_names.usa_1910_current`\n        WHERE state LIKE 'W%'\n        \"\"\".format(project_id = PROJECT_ID, dataset = DATASET, table = TABLE)\n\njob = bq_obj.client.query(QUERY)  # API request.\njob.result()  # Waits for the query to finish.\nprint(job)\n\nQueryJob&lt;project=dz-learning-d, location=US, id=9a4cd539-d063-429d-bff8-1a7b64a6620c&gt;\n\n\nWhich results in a brand new dataset and view on our project: \nExample 2: using the BigQuery client to perform a SQL query and save the results in a dataframe.\n\n# 1. Instantiate object:\nPROJECT_ID = 'dz-learning-d'\nbq_obj = BigQuery(PROJECT_ID)\n\n# 2. Execute SQL and save results in dataframe:\nQUERY = \"\"\"\n        SELECT name FROM `bigquery-public-data.usa_names.usa_1910_2013`\n        WHERE state = \"TX\"\n        LIMIT 100\n        \"\"\"\ndf = bq_obj.client.query(QUERY).to_dataframe()\ndf\n\n\n\n\n\n\n\n\nname\n\n\n\n\n0\nMary\n\n\n1\nRoberta\n\n\n2\nMarguerite\n\n\n3\nKatie\n\n\n4\nEunice\n\n\n...\n...\n\n\n95\nRita\n\n\n96\nElida\n\n\n97\nBillie\n\n\n98\nIda\n\n\n99\nElizabeth\n\n\n\n\n100 rows × 1 columns\n\n\n\n\n# Test [extract_bucket_and_path]:\nt_bucket = 'bucket_name'\nt_path = 'folder_name_1/folder_name_2'\nf_bucket, f_path = extract_bucket_and_path('gs://bucket_name/folder_name_1/folder_name_2')\n\ntest_eq(t_bucket, f_bucket)\ntest_eq(t_path, f_path)\n\n\nsource\n\n\n\n\n Storage (project_id:str)\n\nCloud Storage client generation and additional methods\n\n\n\n\nType\nDetails\n\n\n\n\nproject_id\nstr\nGCP project ID\n\n\n\n\nsource\n\n\n\n\n Storage.download_files (gcs_uri:str, local_dir:str='', verbose:bool=True)\n\nDownload the files from a GCS location to a local directory\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ngcs_uri\nstr\n\nGCS URI. Ex: gs://bucket_name/[folder_name/]\n\n\nlocal_dir\nstr\n\nLocal directory to download the file\n\n\nverbose\nbool\nTrue\nBoolean variable to print paths of files downloaded\n\n\n\n\n# 1. Instantiate object:\nPROJECT_ID = 'dz-learning-d'\nstg_obj = Storage(PROJECT_ID)\n\n# 2. Download files from GCS location to local:\nGCS_URI = 'gs://dz-d-stg-us-testartifacts/gcp-python-client-funtions/01_storage/01_download_files_folder/'\nLOCAL_DIR = 'test_sandbox/01_storage'\n\nres = stg_obj.download_files(GCS_URI, LOCAL_DIR, False)\nprint(res)\n\n# Test [download_files]:\ntest_eq(res, 'No. files downloaded: 4')\n\nNo. files downloaded: 4\n\n\nPortions of this page are modifications based on work created and shared by Google and used according to terms described in the Creative Commons 4.0 Attribution License."
  },
  {
    "objectID": "index.html#installation",
    "href": "index.html#installation",
    "title": "GCP Python Client Functions",
    "section": "Installation",
    "text": "Installation\nLaunch a terminal and install by entering:\npip install gcp_python_client_functions"
  },
  {
    "objectID": "index.html#usage-prerequisites",
    "href": "index.html#usage-prerequisites",
    "title": "GCP Python Client Functions",
    "section": "Usage Prerequisites",
    "text": "Usage Prerequisites\n\n1. GCP environment\n\nCreate a GCP project by going to the Resource Manager page in the cloud console (cloud resources naming convention).\nEnable billing for the project you’ll work with by going to the Cloud Billing page and selecting your project on the top right corner (300 USD free credits are associated with new billing accounts + a big list of free tier products).\nEnable BigQuery API by going to APIs & Services page on the cloud console and looking for the BigQuery API.\n\n\n\n2. Authentication\nAuthenticating by… - (locally) using the Google Cloud SDK(installation needed). Launch a terminal enter:\ngcloud auth login --update-adc\n\n(elsewhere) downloading a service account JSON keyfile and point to it using an environment variable:\n\nexport GOOGLE_APPLICATION_CREDENTIALS=\"/path/to/keyfile.json\"\n\nor through Workflow Identity Provider (what we used to authenticate within GitHub Actions, see Cloud Advocate’s video and stackoverflow question for additional support)."
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "GCP Python Client Functions",
    "section": "How to use",
    "text": "How to use\n\nfrom gcp_python_client_functions.clients import *\n\nPROJECT_ID = 'dz-learning-d'\n\n# BigQuery\nbq_obj = BigQuery(PROJECT_ID)\n\n# Cloud Storage\nstg_obj = Storage(PROJECT_ID)"
  }
]